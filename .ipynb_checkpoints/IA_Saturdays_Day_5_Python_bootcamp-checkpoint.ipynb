{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ta_GgcKniyk"
   },
   "source": [
    "# **Python for data science and data analysis from scratch**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvJPHfudP0cq"
   },
   "source": [
    "## Predicción\n",
    "Para esta sesión usaremos un dataset con los datos de los usuarios de un programa de uso de bicicletas compartidas en la ciudad de Washington y trataremos de pronosticar la demanda que tendrá el servicio en fechas futuras.\n",
    "\n",
    "Este dataset se encuentra disponible de manera gratuita en el repositorio para aprendizaje de Machine Learning de la UCI en la siguiente liga: [https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset ](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aW3Quwp529ed"
   },
   "source": [
    "Librerías que utilizaremos en esta sesión:\n",
    "\n",
    "Numpy\n",
    "\n",
    "Pandas\n",
    "\n",
    "Seaborn\n",
    "\n",
    "sklearn\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Matplot\n",
    "\n",
    "Librería para crear gráficas, puede ser usada con otras librerías de Python, como NumPy.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "SciPy\n",
    "\n",
    "Es una librería libre de código abierto, usada para cómputo científico y técnico. Contiene módulos para optimización, álgebra lineal, procesamiento de imágenes, entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uflfuaOFsEOz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import  linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHc7ZxS0wWMm"
   },
   "outputs": [],
   "source": [
    "params = {'legend.fontsize': 'medium',\n",
    "          'figure.figsize': (15, 8)}\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNSddUub4uzT"
   },
   "source": [
    "\n",
    "## Análisis y preprocesamiento de los datos\n",
    "\n",
    "Primero vamos a leer el dataset y cargarlo en una variable, para ver cuántos registros y atributos contiene.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fET2sYliiW_n"
   },
   "outputs": [],
   "source": [
    " hour_df = pd.read_csv('https://saturdays-ai.s3-us-west-2.amazonaws.com/hour.csv')\n",
    " hour_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "95rFAicJ5Q2S"
   },
   "outputs": [],
   "source": [
    "hour_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fo-Ini-oit34"
   },
   "outputs": [],
   "source": [
    "hour_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J3pMGYy4iymL"
   },
   "source": [
    "Al analizar los tipos de cada atributo nos damos cuenta que la columna de **dteday** fue leída como cadena y será necesario cambiarla a tipo **timestamp**. \n",
    "\n",
    "Los atributos de **season**, **holiday** y **weekday** fueron leídos como enteros y van a requerir ser convertidos a categorías para poder entenderlos apropiadamente.\n",
    "\n",
    "Primero vamos a cambiar los nombres de los atributos para hacerlos más legibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wYBGccNji4RE"
   },
   "outputs": [],
   "source": [
    "hour_df.rename(columns={'instant':'rec_id',\n",
    "                        'dteday':'datetime',\n",
    "                        'holiday':'is_holiday',\n",
    "                        'workingday':'is_workingday',\n",
    "                        'weathersit':'weather_condition',\n",
    "                        'hum':'humidity',\n",
    "                        'mnth':'month',\n",
    "                        'cnt':'total_count',\n",
    "                        'hr':'hour',\n",
    "                        'yr':'year'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYZaKp-ZjDMu"
   },
   "outputs": [],
   "source": [
    "# conversion de cadena a timestamp\n",
    "hour_df['datetime'] = pd.to_datetime(hour_df.datetime)\n",
    "\n",
    "# conversion a tipo categoria\n",
    "hour_df['season'] = hour_df.season.astype('category')\n",
    "hour_df['is_holiday'] = hour_df.is_holiday.astype('category')\n",
    "hour_df['weekday'] = hour_df.weekday.astype('category')\n",
    "hour_df['weather_condition'] = hour_df.weather_condition.astype('category')\n",
    "hour_df['is_workingday'] = hour_df.is_workingday.astype('category')\n",
    "hour_df['month'] = hour_df.month.astype('category')\n",
    "hour_df['year'] = hour_df.year.astype('category')\n",
    "hour_df['hour'] = hour_df.hour.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGiQTWuEjT9D"
   },
   "source": [
    "## Distribución y tendencias\n",
    "\n",
    "Ahora que preprocesamos nuestro dataset podemos visualizarlo. \n",
    "\n",
    "Vamos a empezar visualizando la distribución de viajes por hora durante las diferentes estaciones del año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pYHNhktKjWQ_"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sn.pointplot(data=hour_df[['hour',\n",
    "                           'total_count',\n",
    "                           'season']],\n",
    "             x='hour',y='total_count',\n",
    "             hue='season',ax=ax)\n",
    "ax.set(title=\"Distribución por hora de los viajes de cada estación del año\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ve2RU5S9jtfq"
   },
   "source": [
    "\n",
    "La gráfica nos muestra tendencias similares sin importar la estación del año, tenemos picos entre 7-9 am y entre 4-6 pm, posiblemente por los horarios de oficina.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TzKkG7ETkfXW"
   },
   "source": [
    "Ejercicio\n",
    "1. Crear una gráfica que muestre el número de viajes por día de la semana\n",
    "\n",
    "2. Crear una gráfica para mostrar la cantidad de viajes por mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqpWg-4GkkCm"
   },
   "outputs": [],
   "source": [
    "# 1. Similar a nuestra gráfica: Distribución por hora de los viajes de cada estación del año\n",
    "fig,ax = plt.subplots()\n",
    "sn.pointplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-KdYm3EKnUN"
   },
   "outputs": [],
   "source": [
    "# 2. Podemos utilizar barplot\n",
    "fig,ax = plt.subplots()\n",
    "sn.barplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0BgXJRK2kxoL"
   },
   "source": [
    "## Correlación\n",
    "\n",
    "La correlación nos ayuda a entender las relaciones entre diferentes atributos de nuestros datos.\n",
    "\n",
    "Es importante entender que la correlación no implica causalidad.\n",
    "\n",
    "El siguiente código prepara una matriz correlacional  usando la función **corr()** de pandas. \n",
    "\n",
    "Después usamos una gráfica llamada mapa de calor para mostrar la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZxE5p8rk2gb"
   },
   "outputs": [],
   "source": [
    "corrMatt = hour_df[[\"temp\",\"atemp\",\n",
    "                    \"humidity\",\"windspeed\",\n",
    "                    \"casual\",\"registered\",\n",
    "                    \"total_count\"]].corr()\n",
    "mask = np.array(corrMatt)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "sn.heatmap(corrMatt, mask=mask,\n",
    "           vmax=.8, square=True,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVrf_ojzk5s4"
   },
   "source": [
    "\n",
    "Las dos variables que cuentan los tipos de usuarios muestran una fuerte correlación con el total de los viajes. \n",
    "\n",
    "De manera similar los atributos de temp y atemp muestran una correlación alta, pero ninguno de los otros atributos muestran una correlación alta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jH7Hi0oZlLMp"
   },
   "source": [
    "## Análisis de regresión\n",
    "\n",
    "Es una técnica de modelado estadístico. Comprende el proceso de investigar relaciones entre variables dependientes e independientes.\n",
    "\n",
    "La regresión se refiere a la estimación de variables contínuas, al contrario de la clasificación, que estima variables discretas.\n",
    "\n",
    "La relación de altura y peso es un ejemplo clásico de regresión. Por ejemplo se dice que el peso de una persona depende de su estatura. Por lo tanto, podemos formular una función de regresión para estimar el peso (variable dependiente) de una persona dada su altura (variable independiente).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XIEFEhujlZRU"
   },
   "source": [
    "## Tipos de regresión\n",
    "\n",
    "Todas las técnicas de modelado de regresión involucran lo siguiente:\n",
    "\n",
    "La variable independiente X\n",
    "\n",
    "La variable dependiente u objetivo Y\n",
    "\n",
    "Un parámetro desconocido β \n",
    "\n",
    "Una función de regresión relaciona estas entidades de la siguiente manera:\n",
    "\n",
    "$$ Y=f\\left(X,\\beta \\right) $$\n",
    "\n",
    "La función f() necesita ser especificada o aprendida del dataset.\n",
    "\n",
    "\n",
    "Algunas técnicas de regresión comúnmente usadas son:\n",
    "\n",
    "* **Regresión lineal:** mapea una relación lineal entre las variables dependientes e independientes. La meta es tratar de minimizar el error.\n",
    "\n",
    "* **Regresión logística:** cuando la variable dependiente es binaria (Positivo o Negativo), esta técnica es usada. Esta técnica tiene más en común con técnicas de clasificación que de regresión.\n",
    "\n",
    "* **Regresión no lineal:** para casos en los que la variable dependiente se relaciona de manera polinominal a la variable independiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkfWEt7IlaYp"
   },
   "source": [
    "## Modelado\n",
    "\n",
    "Vamos a empezar a crear un modelo de nuestro dataset para poder predecir la demanda de bicicletas para una fecha específica. \n",
    "\n",
    "Nuestro dataset contiene varias variables categóricas, necesitamos codificar las nominales antes de usarlas en nuestro proceso de modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xm-cCS-USDAf"
   },
   "outputs": [],
   "source": [
    "def fit_transform_ohe(df,col_name):\n",
    "    # codificar la columna\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le_labels = le.fit_transform(df[col_name])\n",
    "    df[col_name+'_label'] = le_labels\n",
    "    \n",
    "    # hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
    "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n",
    "    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
    "    \n",
    "    return le,ohe,features_df\n",
    "\n",
    "def transform_ohe(df,le,ohe,col_name):\n",
    "    # codificado de etiquetas\n",
    "    col_labels = le.transform(df[col_name])\n",
    "    df[col_name+'_label'] = col_labels\n",
    "    \n",
    "    # ohe \n",
    "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
    "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n",
    "    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H9qpQri8SqNq"
   },
   "source": [
    "Para probar nuestro modelo vamos a dividir nuestro dataset en valores para entrenamiento y pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kIoHPiRxcNQ"
   },
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(hour_df.iloc[:,0:-3], hour_df.iloc[:,-1], \n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "X.reset_index(inplace=True)\n",
    "y = y.reset_index()\n",
    "\n",
    "X_test.reset_index(inplace=True)\n",
    "y_test = y_test.reset_index()\n",
    "\n",
    "print(\"Training set::{}{}\".format(X.shape,y.shape))\n",
    "print(\"Testing set::{}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DeDAYO5iTCCW"
   },
   "source": [
    "Ahora vamos a recorrer una lista de variables categóricas para transformar y preparar una lista de atributos codificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDbc9tIgxhZt"
   },
   "outputs": [],
   "source": [
    "cat_attr_list = ['season','is_holiday',\n",
    "                 'weather_condition','is_workingday',\n",
    "                 'hour','weekday','month','year']\n",
    "numeric_feature_cols = ['temp','humidity','windspeed','hour','weekday','month','year']\n",
    "subset_cat_features =  ['season','is_holiday','weather_condition','is_workingday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnhxnLFYxjVr"
   },
   "outputs": [],
   "source": [
    "encoded_attr_list = []\n",
    "for col in cat_attr_list:\n",
    "    return_obj = fit_transform_ohe(X,col)\n",
    "    encoded_attr_list.append({'label_enc':return_obj[0],\n",
    "                              'ohe_enc':return_obj[1],\n",
    "                              'feature_df':return_obj[2],\n",
    "                              'col_name':col})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pee1Y-oGmKdv"
   },
   "source": [
    "En el siguiente paso unimos las categorías numéricas y las codificadas en un dataset que usaremos para nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itOIbQsrxmON"
   },
   "outputs": [],
   "source": [
    "feature_df_list = [X[numeric_feature_cols]]\n",
    "feature_df_list.extend([enc['feature_df'] \\\n",
    "                        for enc in encoded_attr_list \\\n",
    "                        if enc['col_name'] in subset_cat_features])\n",
    "\n",
    "train_df_new = pd.concat(feature_df_list, axis=1)\n",
    "print(\"Shape::{}\".format(train_df_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQbOmxNimY6f"
   },
   "source": [
    "## Entrenamiento\n",
    "\n",
    "En **scikit** tenemos un módulo llamado **linear_model** para crear nuestro modelo de regresión lineal. \n",
    "Como todos los algoritmos de scikit para aprendizaje automático, también usa los métodos **fit()** y **predict()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HBzb-ZOyxof_"
   },
   "outputs": [],
   "source": [
    "X = train_df_new\n",
    "y= y.total_count.values.reshape(-1,1)\n",
    "\n",
    "lin_reg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ulzwXI5Po3ih"
   },
   "source": [
    "Para evitar el overfitting en nuestro moodelo en lugar del método **predict()** usaremos el de validación cruzada **cross_val_predict()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sPJjmrVVxqVY"
   },
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(lin_reg, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3u-mEQdspMrB"
   },
   "source": [
    "Ahora vamos a graficar nuestro modelo para ver su comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vczgMnDNpSB6"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y, y-predicted)\n",
    "ax.axhline(lw=2,color='black')\n",
    "ax.set_xlabel('Observed')\n",
    "ax.set_ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Z757_lQx5w_"
   },
   "outputs": [],
   "source": [
    "lin_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYTAOaNOpfrq"
   },
   "source": [
    "## Pruebas\n",
    "\n",
    "El modelo de regresión lineal que ya entrenamos necesita ser validado con un dataset que no ha leído, este dataset ya lo hemos construido previamente con el método de **train_test_split()**.\n",
    "\n",
    "Pero antes, tenemos que procesarlo de la misma manera que hicimos con el dataset de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfVALCmtx75X"
   },
   "outputs": [],
   "source": [
    "test_encoded_attr_list = []\n",
    "for enc in encoded_attr_list:\n",
    "    col_name = enc['col_name']\n",
    "    le = enc['label_enc']\n",
    "    ohe = enc['ohe_enc']\n",
    "    test_encoded_attr_list.append({'feature_df':transform_ohe(X_test,\n",
    "                                                              le,ohe,\n",
    "                                                              col_name),\n",
    "                                   'col_name':col_name})\n",
    "    \n",
    "    \n",
    "test_feature_df_list = [X_test[numeric_feature_cols]]\n",
    "test_feature_df_list.extend([enc['feature_df'] \\\n",
    "                             for enc in test_encoded_attr_list \\\n",
    "                             if enc['col_name'] in subset_cat_features])\n",
    "\n",
    "test_df_new = pd.concat(test_feature_df_list, axis=1) \n",
    "print(\"Shape::{}\".format(test_df_new.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsCtrkBnx-CJ"
   },
   "outputs": [],
   "source": [
    "test_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3ph3aWmqvOm"
   },
   "source": [
    "Para el último paso, vamos a usar el método de **predict()** y comparar nuestros resultados para conocer el desempeño de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hupBIYVPyAe2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_test = test_df_new\n",
    "y_test = y_test.total_count.values.reshape(-1,1)\n",
    "\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "residuals = y_test-y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJbx-v4CyCtA"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r2_score = lin_reg.score(X_test,y_test)\n",
    "print(\"R-squared::{}\".format(r2_score))\n",
    "print(\"MSE: %.2f\"\n",
    "      % metrics.mean_squared_error(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msHMFjXOyEsz"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, residuals)\n",
    "ax.axhline(lw=2,color='black')\n",
    "ax.set_xlabel('Observed')\n",
    "ax.set_ylabel('Residuals')\n",
    "ax.title.set_text(\"Residual Plot with R-Squared={}\".format(np.average(r2_score)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72B2KnCCt9lx"
   },
   "source": [
    "Ejercicio\n",
    "\n",
    "Probar otros modelos de regresión (árbol de decisiones)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IA_Saturdays_Day_5_Python_bootcamp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
